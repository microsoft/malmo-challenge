[BASIC]
learner = DoubleDQN
network = DuelingRecNN
optimizer = Adam
load_path =
grad_clip = 5.
simulator = FixedOpponentSimulatorMDP
eval_episodes = 50000

[MEMORY_BUFFER]
buffer_size = 1000000
episodic_buffer_size = 50000
wait_priority_after_sampling = False

[SIMULATOR]
size = 7
state_dim = 86
frames_no = 1

[OPTIMIZER]
alpha = 0.001
beta1 = 0.9

[NETWORK]
input_dim = 86
output_dim = 3
w_scale = 1.
hidden_units = 256
activation = relu

[ALGORITHM]
gpu = -1
gamma = 1
replay_start_size = 256
minibatch_size = 32
target_update_frequency = 10000
n_times_update = 1
update_frequency = 100
episodic_update = 1

[EXPLORER]
start_epsilon = 0.1
end_epsilon = 0.0
decay_steps = 1000000

[EXPERIMENT]
steps = 1000000
eval_n_runs = 1000
eval_frequency = 20000
max_episode_len = 25